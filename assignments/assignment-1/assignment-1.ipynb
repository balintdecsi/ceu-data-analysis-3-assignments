{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a3f4b3",
   "metadata": {},
   "source": [
    "# Assignment 1: Airbnb Pricing Model\n",
    "\n",
    "**Student Name**: Bálint Décsi  \n",
    "**Objective**: Build a prediction model for Airbnb listing prices  \n",
    "**Data**: Copenhagen (March 2025 for training, September 2025 for temporal validation) and Oslo (September 2025 for spatial validation)  \n",
    "**Course**: CEU Data Analysis 3 - Prediction and Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### A note on the data\n",
    "\n",
    "All datasets come from [Inside Airbnb](http://insideairbnb.com/get-the-data/), which scrapes Airbnb listings quarterly. I'm using three separate scrapes:\n",
    "\n",
    "| Dataset | Date | Purpose |\n",
    "|---------|------|---------|\n",
    "| Copenhagen | March 2025 | Training |\n",
    "| Copenhagen | September 2025 | Temporal validation |\n",
    "| Oslo | September 2025 | Spatial validation |\n",
    "\n",
    "This setup gives us **proper temporal validation** — we're training on Q1 data and testing on Q3 data from the same city. Six months is enough time for market conditions to shift (seasonal pricing, new listings, hosts adjusting strategies). If the model generalizes across time, it suggests we've captured durable pricing patterns rather than just memorizing a snapshot.\n",
    "\n",
    "The Oslo data tests **spatial generalization** — can a model trained on Copenhagen predict prices in a different Nordic capital? Same time period (Sept 2025), different market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings as per course convention\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Statistical modeling (course uses statsmodels for OLS)\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# For design matrices (as used in course material)\n",
    "from patsy import dmatrices\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fa317",
   "metadata": {},
   "source": [
    "## Part I: Task 1 - Data Acquisition & Preparation\n",
    "\n",
    "### Data Loading\n",
    "\n",
    "Three datasets from Inside Airbnb:\n",
    "- **Copenhagen March 2025**: Training set (≥10,000 listings target)\n",
    "- **Copenhagen September 2025**: Temporal validation (same city, 6 months later)\n",
    "- **Oslo September 2025**: Spatial validation (different city, same time period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from Inside Airbnb (if not already present)\n",
    "# This runs the fetch_data.py script from the project root\n",
    "!python ../../scripts/fetch_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d646461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using cross-platform paths\n",
    "# Three datasets: train (CPH March), temporal test (CPH Sept), spatial test (Oslo Sept)\n",
    "path_train = os.path.join(os.pardir, os.pardir, 'data', 'raw', 'copenhagen_listings_2025_03_train.csv')\n",
    "path_temporal = os.path.join(os.pardir, os.pardir, 'data', 'raw', 'copenhagen_listings_2025_09_test.csv')\n",
    "path_spatial = os.path.join(os.pardir, os.pardir, 'data', 'raw', 'oslo_listings_2025_09_test.csv')\n",
    "\n",
    "df_train_raw = pd.read_csv(path_train)\n",
    "df_temporal_raw = pd.read_csv(path_temporal)\n",
    "df_spatial_raw = pd.read_csv(path_spatial)\n",
    "\n",
    "print(f\"Copenhagen March 2025 (train): {df_train_raw.shape[0]:,} rows, {df_train_raw.shape[1]} columns\")\n",
    "print(f\"Copenhagen Sept 2025 (temporal test): {df_temporal_raw.shape[0]:,} rows, {df_temporal_raw.shape[1]} columns\")\n",
    "print(f\"Oslo Sept 2025 (spatial test): {df_spatial_raw.shape[0]:,} rows, {df_spatial_raw.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb01cf",
   "metadata": {},
   "source": [
    "### About the validation strategy\n",
    "\n",
    "I went with Copenhagen as the training city because it has more listings than Oslo, which helps meet the ≥10,000 training observations requirement. The validation setup is:\n",
    "\n",
    "1. **Temporal validation**: Copenhagen Sept 2025 vs Copenhagen March 2025. This is a proper 6-month time gap — enough for seasonal effects, new hosts entering the market, and price adjustments. If the model holds up, it's not just fitting to a single moment in time.\n",
    "\n",
    "2. **Spatial validation**: Oslo Sept 2025. Same time period as the temporal test, but different city. This isolates the \"geography effect\" from the \"time effect\". If spatial validation is worse than temporal, it tells us location-specific factors matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290740ee",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic info about training data (Copenhagen March 2025)\n",
    "df_train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa7806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine target variable (price)\n",
    "# Price is stored as string with $ and commas, need to clean\n",
    "print(\"Price column sample (Copenhagen March 2025):\")\n",
    "print(df_train_raw['price'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa0c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price_str):\n",
    "    \"\"\"Convert price string like '$1,234.00' to float\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    return float(str(price_str).replace('$', '').replace(',', ''))\n",
    "\n",
    "# Apply to all three datasets\n",
    "df_train_raw['price_clean'] = df_train_raw['price'].apply(clean_price)\n",
    "df_temporal_raw['price_clean'] = df_temporal_raw['price'].apply(clean_price)\n",
    "df_spatial_raw['price_clean'] = df_spatial_raw['price'].apply(clean_price)\n",
    "\n",
    "print(\"Copenhagen March 2025 (train) price statistics:\")\n",
    "print(df_train_raw['price_clean'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution comparison across all datasets\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "axes[0].hist(df_train_raw['price_clean'].dropna(), bins=50, edgecolor='black', color='steelblue')\n",
    "axes[0].set_title('Copenhagen March 2025 (Train)')\n",
    "axes[0].set_xlabel('Price')\n",
    "\n",
    "axes[1].hist(df_temporal_raw['price_clean'].dropna(), bins=50, edgecolor='black', color='darkorange')\n",
    "axes[1].set_title('Copenhagen Sept 2025 (Temporal Test)')\n",
    "axes[1].set_xlabel('Price')\n",
    "\n",
    "axes[2].hist(df_spatial_raw['price_clean'].dropna(), bins=50, edgecolor='black', color='green')\n",
    "axes[2].set_title('Oslo Sept 2025 (Spatial Test)')\n",
    "axes[2].set_xlabel('Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31e083",
   "metadata": {},
   "source": [
    "### Data Wrangling Function\n",
    "\n",
    "Creating a reusable function to ensure consistent preprocessing across train and test sets.\n",
    "\n",
    "**Key preprocessing decisions:**\n",
    "\n",
    "1. **Price filtering**: I use percentile-based cutoffs (1st to 99th percentile) rather than hard-coded thresholds. This is more robust because the price distributions differ between cities. Also dropped anything under $20/night — those are probably errors or weird promotional listings.\n",
    "\n",
    "2. **Accommodates filter**: Capped at <8 people, following the class-14 example. Most Airbnbs are for small groups; the handful of 16-person party houses would be outliers that could skew the model.\n",
    "\n",
    "3. **Missing value strategy**: Median imputation for numeric vars, plus flag variables for review-related missingness. New listings won't have reviews, so the \"no review score\" pattern is actually meaningful information — not just noise to impute away.\n",
    "\n",
    "4. **Feature engineering**: Squared term for accommodates (non-linear pricing), extracted bathroom count from messy text field, binary amenity indicators for things guests actually care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ead92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_airbnb(df, is_train=True, reference_df=None):\n",
    "    \"\"\"\n",
    "    Preprocess Airbnb data for modeling.\n",
    "    Following course material patterns from class-14 and class-16.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Raw Airbnb data\n",
    "    is_train : bool - Whether this is training data (affects imputation)\n",
    "    reference_df : DataFrame - Reference for imputation values (use training data)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with cleaned and engineered features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # =====================================================\n",
    "    # 1. Clean price (target variable)\n",
    "    # =====================================================\n",
    "    df['price'] = df['price'].apply(clean_price)\n",
    "    \n",
    "    # Drop if no target (as per course: \"drop if no target\")\n",
    "    df = df.dropna(subset=['price'])\n",
    "    \n",
    "    # =====================================================\n",
    "    # 2. Sample design - filter extreme values\n",
    "    # Following class-14: df=df.loc[df.n_accommodates < 8]\n",
    "    # =====================================================\n",
    "    df = df[df['accommodates'] < 8]\n",
    "    \n",
    "    # Filter extreme prices using percentiles (more robust)\n",
    "    # Following class-14 pattern: check quantiles then filter\n",
    "    # Keep 1st to 99th percentile to remove outliers\n",
    "    price_lower = df['price'].quantile(0.01)\n",
    "    price_upper = df['price'].quantile(0.99)\n",
    "    df = df[(df['price'] >= price_lower) & (df['price'] <= price_upper)]\n",
    "    \n",
    "    # Also apply minimum threshold (avoid free/near-free listings)\n",
    "    df = df[df['price'] >= 20]\n",
    "    \n",
    "    # =====================================================\n",
    "    # 3. Handle missing values\n",
    "    # Following course pattern: \n",
    "    #   - fillna with median for numeric\n",
    "    #   - fillna with mode/string for categorical\n",
    "    #   - create flags for important missing patterns\n",
    "    # =====================================================\n",
    "    \n",
    "    # Numeric columns - use median imputation (np.nanmedian pattern from course)\n",
    "    numeric_cols = [\n",
    "        'accommodates', 'bedrooms', 'beds', \n",
    "        'minimum_nights', 'maximum_nights',\n",
    "        'number_of_reviews', 'reviews_per_month',\n",
    "        'review_scores_rating', 'review_scores_accuracy', \n",
    "        'review_scores_cleanliness', 'review_scores_checkin',\n",
    "        'review_scores_communication', 'review_scores_location', \n",
    "        'review_scores_value',\n",
    "        'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "        'calculated_host_listings_count'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            # Get median from reference (training) data or current data\n",
    "            if is_train or reference_df is None:\n",
    "                median_val = np.nanmedian(df[col])\n",
    "            else:\n",
    "                median_val = np.nanmedian(reference_df[col])\n",
    "            \n",
    "            # Create flag for review-related missing (important pattern from course)\n",
    "            if col.startswith('review_scores') or col == 'reviews_per_month':\n",
    "                flag_name = f'flag_{col}'\n",
    "                df[flag_name] = df[col].isna().astype(int)\n",
    "            \n",
    "            # Impute with median\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 4. Categorical features - fillna with \"Missing\"\n",
    "    # =====================================================\n",
    "    cat_cols = ['room_type', 'property_type', 'neighbourhood_cleansed']\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('Missing')\n",
    "    \n",
    "    # Create factor variables with f_ prefix (course convention)\n",
    "    df['f_room_type'] = df['room_type']\n",
    "    df['f_property_type'] = df['property_type']\n",
    "    df['f_neighbourhood_cleansed'] = df['neighbourhood_cleansed']\n",
    "    \n",
    "    # =====================================================\n",
    "    # 5. Feature engineering - following course patterns\n",
    "    # =====================================================\n",
    "    \n",
    "    # Numeric features with n_ prefix (course convention)\n",
    "    df['n_accommodates'] = df['accommodates']\n",
    "    df['n_beds'] = df['beds']\n",
    "    df['n_number_of_reviews'] = df['number_of_reviews']\n",
    "    df['n_review_scores_rating'] = df['review_scores_rating']\n",
    "    df['n_reviews_per_month'] = df['reviews_per_month']\n",
    "    df['n_days_since'] = df['availability_365']  # proxy for activity\n",
    "    \n",
    "    # Polynomial terms (from class-13: df['agesq'] = df['age'] ** 2)\n",
    "    df['n_accommodates2'] = df['n_accommodates'] ** 2\n",
    "    \n",
    "    # Extract number of bathrooms from text\n",
    "    if 'bathrooms_text' in df.columns:\n",
    "        df['n_bathrooms'] = df['bathrooms_text'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "        df['n_bathrooms'] = df['n_bathrooms'].fillna(1)\n",
    "        df['d_shared_bath'] = df['bathrooms_text'].str.contains('shared', case=False, na=False).astype(int)\n",
    "    else:\n",
    "        df['n_bathrooms'] = 1\n",
    "        df['d_shared_bath'] = 0\n",
    "    \n",
    "    # Boolean to dummy (d_ prefix for dummies, course convention)\n",
    "    df['d_host_is_superhost'] = (df['host_is_superhost'] == 't').astype(int)\n",
    "    df['d_instant_bookable'] = (df['instant_bookable'] == 't').astype(int)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 6. Amenities extraction (key features as dummies)\n",
    "    # Following class-14 pattern: d_ prefix for dummy variables\n",
    "    # =====================================================\n",
    "    if 'amenities' in df.columns:\n",
    "        df['n_amenities'] = df['amenities'].str.count(',') + 1\n",
    "        df['n_amenities'] = df['n_amenities'].fillna(0)\n",
    "        \n",
    "        # Key amenities as binary features\n",
    "        amenity_list = [\n",
    "            'wifi', 'kitchen', 'washer', 'dryer', 'parking', \n",
    "            'air conditioning', 'heating', 'tv', 'pool', 'gym',\n",
    "            'elevator', 'doorman', 'breakfast', 'hot tub', 'fireplace'\n",
    "        ]\n",
    "        for amenity in amenity_list:\n",
    "            col_name = 'd_' + amenity.replace(' ', '_').replace('/', '_')\n",
    "            df[col_name] = df['amenities'].str.lower().str.contains(amenity, na=False).astype(int)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 7. Log transform price (following course: ln_price)\n",
    "    # =====================================================\n",
    "    df['ln_price'] = np.log(df['price'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009876ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to training data (Copenhagen March 2025)\n",
    "df_train = preprocess_airbnb(df_train_raw, is_train=True)\n",
    "print(f\"Copenhagen March 2025 (train) after preprocessing: {df_train.shape[0]:,} rows\")\n",
    "print(f\"\\nPrice statistics after cleaning:\")\n",
    "print(df_train['price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c15511",
   "metadata": {},
   "source": [
    "### Preparing Validation Sets\n",
    "\n",
    "Now we preprocess the two test datasets using the training data as reference. This ensures consistent imputation values (medians computed from training data) are applied to the test sets — avoiding data leakage.\n",
    "\n",
    "**Key point**: This is proper external validation, not just a random holdout:\n",
    "- Temporal test: Copenhagen listings scraped 6 months after training data\n",
    "- Spatial test: Oslo listings from the same time as temporal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Preprocess validation datasets using training data as reference\n",
    "# =====================================================\n",
    "\n",
    "# Temporal validation: Copenhagen September 2025\n",
    "df_temporal = preprocess_airbnb(df_temporal_raw, is_train=False, reference_df=df_train)\n",
    "print(f\"Copenhagen Sept 2025 (temporal test) after preprocessing: {df_temporal.shape[0]:,} rows\")\n",
    "\n",
    "# Spatial validation: Oslo September 2025\n",
    "df_spatial = preprocess_airbnb(df_spatial_raw, is_train=False, reference_df=df_train)\n",
    "print(f\"Oslo Sept 2025 (spatial test) after preprocessing: {df_spatial.shape[0]:,} rows\")\n",
    "\n",
    "# =====================================================\n",
    "# Harmonize categorical levels across all datasets\n",
    "# Replace unseen categories with \"Other\" to avoid patsy errors\n",
    "# =====================================================\n",
    "cat_vars = ['f_property_type', 'f_room_type']\n",
    "\n",
    "for col in cat_vars:\n",
    "    # Get categories from training data\n",
    "    train_categories = set(df_train[col].unique())\n",
    "    \n",
    "    # Replace unseen categories in temporal set\n",
    "    df_temporal[col] = df_temporal[col].apply(\n",
    "        lambda x: x if x in train_categories else 'Other'\n",
    "    )\n",
    "    \n",
    "    # Replace unseen categories in spatial set\n",
    "    df_spatial[col] = df_spatial[col].apply(\n",
    "        lambda x: x if x in train_categories else 'Other'\n",
    "    )\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL DATASET SIZES:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training set (Copenhagen March 2025): {df_train.shape[0]:,} rows\")\n",
    "print(f\"Temporal validation (Copenhagen Sept 2025): {df_temporal.shape[0]:,} rows\")\n",
    "print(f\"Spatial validation (Oslo Sept 2025): {df_spatial.shape[0]:,} rows\")\n",
    "\n",
    "# Show category alignment\n",
    "print(f\"\\nProperty types in train: {df_train['f_property_type'].nunique()}\")\n",
    "print(f\"Property types in temporal: {df_temporal['f_property_type'].nunique()}\")\n",
    "print(f\"Property types in spatial: {df_spatial['f_property_type'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b85188",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "**Variable selection rationale:**\n",
    "- **Property characteristics**: accommodates, bedrooms, beds, bathrooms (core drivers of price)\n",
    "- **Review metrics**: scores and counts (signal of quality)\n",
    "- **Availability**: indicates demand patterns\n",
    "- **Host features**: superhost status, listing count (professionalism)\n",
    "- **Amenities**: key amenities as binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Define predictor groups (following class-16 pattern)\n",
    "# =====================================================\n",
    "\n",
    "# Basic variables (similar to class-16: basic_vars)\n",
    "basic_vars = [\n",
    "    'n_accommodates',\n",
    "    'n_beds', \n",
    "    'n_bathrooms',\n",
    "    'f_property_type',\n",
    "    'f_room_type',\n",
    "]\n",
    "\n",
    "# Reviews (similar to class-16 pattern)\n",
    "reviews = [\n",
    "    'n_number_of_reviews',\n",
    "    'n_review_scores_rating',\n",
    "    'flag_review_scores_rating',\n",
    "    'n_reviews_per_month',\n",
    "]\n",
    "\n",
    "# Polynomial terms\n",
    "poly_vars = ['n_accommodates2']\n",
    "\n",
    "# Dummy variables (d_ prefix convention)\n",
    "amenities = [col for col in df_train.columns if col.startswith('d_')]\n",
    "\n",
    "# Host features\n",
    "host_vars = ['d_host_is_superhost', 'd_instant_bookable']\n",
    "\n",
    "# All predictors for models\n",
    "predictors_1 = basic_vars  # Simple model\n",
    "predictors_2 = basic_vars + reviews + poly_vars + amenities + host_vars  # Full model\n",
    "\n",
    "print(f\"Predictor set 1 (basic): {len(predictors_1)} variables\")\n",
    "print(f\"Predictor set 2 (full): {len(predictors_2)} variables\")\n",
    "print(f\"\\nAmenity dummies found: {len(amenities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Prepare design matrices using patsy (as in class-16)\n",
    "# dmatrices() constructs design matrices given a formula\n",
    "# =====================================================\n",
    "\n",
    "# Build formula string (following course pattern)\n",
    "formula = \"price ~ \" + \" + \".join(predictors_2)\n",
    "print(f\"Formula: {formula[:100]}...\")\n",
    "\n",
    "# Create design matrices for training data\n",
    "y_train, X_train = dmatrices(formula, df_train, return_type='dataframe')\n",
    "y_train = y_train.values.ravel()  # Flatten to 1D array\n",
    "\n",
    "# Create design matrices for validation sets (must have same columns)\n",
    "y_temporal, X_temporal = dmatrices(formula, df_temporal, return_type='dataframe')\n",
    "y_temporal = y_temporal.values.ravel()\n",
    "\n",
    "y_spatial, X_spatial = dmatrices(formula, df_spatial, return_type='dataframe')\n",
    "y_spatial = y_spatial.values.ravel()\n",
    "\n",
    "# Align columns across datasets (handle unseen categories)\n",
    "common_cols = X_train.columns.intersection(X_temporal.columns).intersection(X_spatial.columns)\n",
    "X_train = X_train[common_cols]\n",
    "X_temporal = X_temporal[common_cols]\n",
    "X_spatial = X_spatial[common_cols]\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_train.shape}\")\n",
    "print(f\"Number of features: {len(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30435996",
   "metadata": {},
   "source": [
    "## Part I: Task 2 - Build 5 Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Helper functions for model evaluation\n",
    "# Using statsmodels rmse (as in course material)\n",
    "# =====================================================\n",
    "\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Calculate RMSE, R², MAE for predictions\"\"\"\n",
    "    rmse_val = rmse(y_true, y_pred)\n",
    "    r2_val = r2_score(y_true, y_pred)\n",
    "    mae_val = mean_absolute_error(y_true, y_pred)\n",
    "    return {'Dataset': dataset_name, 'RMSE': rmse_val, 'R2': r2_val, 'MAE': mae_val}\n",
    "\n",
    "# Store results for horserace table\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978aaf9",
   "metadata": {},
   "source": [
    "### Model a: OLS (Baseline)\n",
    "\n",
    "Using `statsmodels` for OLS regression as demonstrated in course material (class-13, class-14).\n",
    "This allows for robust standard errors and detailed regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# OLS Model using statsmodels (as in course material)\n",
    "# Following class-14 pattern with smf.ols()\n",
    "# =====================================================\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Use statsmodels OLS with formula interface\n",
    "ols_formula = \"price ~ \" + \" + \".join(predictors_2)\n",
    "ols_model = smf.ols(ols_formula, data=df_train).fit()\n",
    "\n",
    "ols_train_time = time.time() - start_time\n",
    "\n",
    "# Print summary (as shown in course material)\n",
    "print(ols_model.summary().tables[0])\n",
    "print(f\"\\nR-squared: {ols_model.rsquared:.4f}\")\n",
    "print(f\"Number of observations: {ols_model.nobs:.0f}\")\n",
    "print(f\"Number of variables: {ols_model.df_model:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0847ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate OLS on all datasets\n",
    "# Use design matrices (X_train, etc.) for consistent prediction across datasets\n",
    "# This avoids patsy issues with unseen categorical levels\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit sklearn OLS using the design matrices (equivalent to statsmodels OLS)\n",
    "ols_sklearn = LinearRegression()\n",
    "ols_sklearn.fit(X_train, y_train)\n",
    "\n",
    "ols_pred_train = ols_sklearn.predict(X_train)\n",
    "ols_pred_temporal = ols_sklearn.predict(X_temporal)\n",
    "ols_pred_spatial = ols_sklearn.predict(X_spatial)\n",
    "\n",
    "ols_train_metrics = evaluate_model(y_train, ols_pred_train, 'Train')\n",
    "ols_temporal_metrics = evaluate_model(y_temporal, ols_pred_temporal, 'Temporal')\n",
    "ols_spatial_metrics = evaluate_model(y_spatial, ols_pred_spatial, 'Spatial')\n",
    "\n",
    "ols_inference_time = time.time() - start_time\n",
    "\n",
    "results.append({\n",
    "    'Model': 'OLS',\n",
    "    'Train_RMSE': ols_train_metrics['RMSE'],\n",
    "    'Train_R2': ols_train_metrics['R2'],\n",
    "    'Temporal_RMSE': ols_temporal_metrics['RMSE'],\n",
    "    'Temporal_R2': ols_temporal_metrics['R2'],\n",
    "    'Spatial_RMSE': ols_spatial_metrics['RMSE'],\n",
    "    'Spatial_R2': ols_spatial_metrics['R2'],\n",
    "    'Train_Time': ols_train_time,\n",
    "    'Inference_Time': ols_inference_time\n",
    "})\n",
    "\n",
    "print(f\"OLS Model trained in {ols_train_time:.4f}s\")\n",
    "print(f\"Train RMSE: {ols_train_metrics['RMSE']:.2f}, R²: {ols_train_metrics['R2']:.4f}\")\n",
    "print(f\"Temporal RMSE: {ols_temporal_metrics['RMSE']:.2f}, R²: {ols_temporal_metrics['R2']:.4f}\")\n",
    "print(f\"Spatial RMSE: {ols_spatial_metrics['RMSE']:.2f}, R²: {ols_spatial_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe343d2",
   "metadata": {},
   "source": [
    "### Model b: LASSO (L1 Regularization)\n",
    "\n",
    "Using LASSO with cross-validation as demonstrated in class-14.\n",
    "LASSO performs variable selection by shrinking some coefficients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# LASSO Model (following class-14 pattern)\n",
    "# StandardScaler required before LASSO (as in course)\n",
    "# =====================================================\n",
    "\n",
    "# Scale features (required for LASSO, as shown in class-14)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_temporal_scaled = scaler.transform(X_temporal)\n",
    "X_spatial_scaled = scaler.transform(X_spatial)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# LASSO with cross-validation (similar to course approach)\n",
    "# Using LassoCV which automatically selects best alpha\n",
    "lasso_model = LassoCV(cv=5, random_state=20250224, max_iter=10000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "lasso_train_time = time.time() - start_time\n",
    "\n",
    "print(f\"Optimal alpha (lambda): {lasso_model.alpha_:.6f}\")\n",
    "print(f\"Non-zero coefficients: {np.sum(lasso_model.coef_ != 0)} out of {len(lasso_model.coef_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8650eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LASSO\n",
    "start_time = time.time()\n",
    "\n",
    "lasso_pred_train = lasso_model.predict(X_train_scaled)\n",
    "lasso_pred_temporal = lasso_model.predict(X_temporal_scaled)\n",
    "lasso_pred_spatial = lasso_model.predict(X_spatial_scaled)\n",
    "\n",
    "lasso_train_metrics = evaluate_model(y_train, lasso_pred_train, 'Train')\n",
    "lasso_temporal_metrics = evaluate_model(y_temporal, lasso_pred_temporal, 'Temporal')\n",
    "lasso_spatial_metrics = evaluate_model(y_spatial, lasso_pred_spatial, 'Spatial')\n",
    "\n",
    "lasso_inference_time = time.time() - start_time\n",
    "\n",
    "results.append({\n",
    "    'Model': 'LASSO',\n",
    "    'Train_RMSE': lasso_train_metrics['RMSE'],\n",
    "    'Train_R2': lasso_train_metrics['R2'],\n",
    "    'Temporal_RMSE': lasso_temporal_metrics['RMSE'],\n",
    "    'Temporal_R2': lasso_temporal_metrics['R2'],\n",
    "    'Spatial_RMSE': lasso_spatial_metrics['RMSE'],\n",
    "    'Spatial_R2': lasso_spatial_metrics['R2'],\n",
    "    'Train_Time': lasso_train_time,\n",
    "    'Inference_Time': lasso_inference_time\n",
    "})\n",
    "\n",
    "print(f\"\\nLASSO Model trained in {lasso_train_time:.4f}s\")\n",
    "print(f\"Train RMSE: {lasso_train_metrics['RMSE']:.2f}, R²: {lasso_train_metrics['R2']:.4f}\")\n",
    "print(f\"Temporal RMSE: {lasso_temporal_metrics['RMSE']:.2f}, R²: {lasso_temporal_metrics['R2']:.4f}\")\n",
    "print(f\"Spatial RMSE: {lasso_spatial_metrics['RMSE']:.2f}, R²: {lasso_spatial_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba9776",
   "metadata": {},
   "source": [
    "### Model c: Random Forest\n",
    "\n",
    "Using `RandomForestRegressor` with `GridSearchCV` as demonstrated in class-16.\n",
    "We tune `max_features` and `min_samples_leaf` following the course approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88394f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Random Forest with GridSearchCV (following class-16)\n",
    "# Tuning max_features and min_samples_leaf\n",
    "# =====================================================\n",
    "\n",
    "import math\n",
    "\n",
    "# Theoretical recommended number of features (from class-16)\n",
    "print(f'Theoretical recommended max_features: {math.sqrt(X_train.shape[1]):.2f}')\n",
    "\n",
    "# Initialize Random Forest\n",
    "rfr = RandomForestRegressor(random_state=20250224, n_jobs=-1)\n",
    "\n",
    "# Define tuning grid (following class-16 pattern)\n",
    "tune_grid = {\n",
    "    \"max_features\": [6, 8, 10, 12],\n",
    "    \"min_samples_leaf\": [5, 10, 15]\n",
    "}\n",
    "\n",
    "# GridSearchCV (as in class-16)\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rfr,\n",
    "    param_grid=tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model = rf_grid.fit(X_train, y_train)\n",
    "rf_train_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nBest parameters: {rf_model.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-rf_model.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display CV results (following class-16 pattern)\n",
    "df_rf_cv_results = pd.DataFrame(rf_model.cv_results_)[[\n",
    "    'param_max_features', 'param_min_samples_leaf', 'mean_test_score'\n",
    "]]\n",
    "df_rf_cv_results.columns = ['max_features', 'min_samples_leaf', 'RMSE']\n",
    "df_rf_cv_results['RMSE'] = -df_rf_cv_results['RMSE']  # Convert to positive\n",
    "\n",
    "# Pivot table (as in class-16)\n",
    "df_rf_cv_results.pivot(\n",
    "    index='max_features', \n",
    "    columns='min_samples_leaf', \n",
    "    values='RMSE'\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96cd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest (using best estimator)\n",
    "start_time = time.time()\n",
    "\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_temporal = rf_model.predict(X_temporal)\n",
    "rf_pred_spatial = rf_model.predict(X_spatial)\n",
    "\n",
    "rf_train_metrics = evaluate_model(y_train, rf_pred_train, 'Train')\n",
    "rf_temporal_metrics = evaluate_model(y_temporal, rf_pred_temporal, 'Temporal')\n",
    "rf_spatial_metrics = evaluate_model(y_spatial, rf_pred_spatial, 'Spatial')\n",
    "\n",
    "rf_inference_time = time.time() - start_time\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Train_RMSE': rf_train_metrics['RMSE'],\n",
    "    'Train_R2': rf_train_metrics['R2'],\n",
    "    'Temporal_RMSE': rf_temporal_metrics['RMSE'],\n",
    "    'Temporal_R2': rf_temporal_metrics['R2'],\n",
    "    'Spatial_RMSE': rf_spatial_metrics['RMSE'],\n",
    "    'Spatial_R2': rf_spatial_metrics['R2'],\n",
    "    'Train_Time': rf_train_time,\n",
    "    'Inference_Time': rf_inference_time\n",
    "})\n",
    "\n",
    "print(f\"Random Forest trained in {rf_train_time:.2f}s\")\n",
    "print(f\"Train RMSE: {rf_train_metrics['RMSE']:.2f}, R²: {rf_train_metrics['R2']:.4f}\")\n",
    "print(f\"Temporal RMSE: {rf_temporal_metrics['RMSE']:.2f}, R²: {rf_temporal_metrics['R2']:.4f}\")\n",
    "print(f\"Spatial RMSE: {rf_spatial_metrics['RMSE']:.2f}, R²: {rf_spatial_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd121cd8",
   "metadata": {},
   "source": [
    "### Model d: Gradient Boosting\n",
    "\n",
    "Using `GradientBoostingRegressor` with hyperparameter tuning.\n",
    "This is one of the boosting methods mentioned in the assignment requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Gradient Boosting with GridSearchCV\n",
    "# =====================================================\n",
    "\n",
    "# Initialize Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(random_state=20250224)\n",
    "\n",
    "# Define tuning grid\n",
    "gb_tune_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"min_samples_leaf\": [5, 10]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "gb_grid = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_grid=gb_tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "gb_model = gb_grid.fit(X_train, y_train)\n",
    "gb_train_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nBest parameters: {gb_model.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-gb_model.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Gradient Boosting\n",
    "start_time = time.time()\n",
    "\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_temporal = gb_model.predict(X_temporal)\n",
    "gb_pred_spatial = gb_model.predict(X_spatial)\n",
    "\n",
    "gb_train_metrics = evaluate_model(y_train, gb_pred_train, 'Train')\n",
    "gb_temporal_metrics = evaluate_model(y_temporal, gb_pred_temporal, 'Temporal')\n",
    "gb_spatial_metrics = evaluate_model(y_spatial, gb_pred_spatial, 'Spatial')\n",
    "\n",
    "gb_inference_time = time.time() - start_time\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'Train_RMSE': gb_train_metrics['RMSE'],\n",
    "    'Train_R2': gb_train_metrics['R2'],\n",
    "    'Temporal_RMSE': gb_temporal_metrics['RMSE'],\n",
    "    'Temporal_R2': gb_temporal_metrics['R2'],\n",
    "    'Spatial_RMSE': gb_spatial_metrics['RMSE'],\n",
    "    'Spatial_R2': gb_spatial_metrics['R2'],\n",
    "    'Train_Time': gb_train_time,\n",
    "    'Inference_Time': gb_inference_time\n",
    "})\n",
    "\n",
    "print(f\"Gradient Boosting trained in {gb_train_time:.2f}s\")\n",
    "print(f\"Train RMSE: {gb_train_metrics['RMSE']:.2f}, R²: {gb_train_metrics['R2']:.4f}\")\n",
    "print(f\"Temporal RMSE: {gb_temporal_metrics['RMSE']:.2f}, R²: {gb_temporal_metrics['R2']:.4f}\")\n",
    "print(f\"Spatial RMSE: {gb_spatial_metrics['RMSE']:.2f}, R²: {gb_spatial_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae52944",
   "metadata": {},
   "source": [
    "### Model e: Ridge Regression (Custom Choice)\n",
    "\n",
    "**Rationale**: Ridge regression (L2 regularization) is a natural comparison to LASSO. \n",
    "While LASSO performs variable selection (sets coefficients to zero), Ridge shrinks all coefficients \n",
    "toward zero but doesn't eliminate any. This often works better when predictors are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2818858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Ridge Regression with cross-validation\n",
    "# =====================================================\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Ridge with CV to find optimal alpha\n",
    "ridge_model = RidgeCV(cv=5, alphas=np.logspace(-3, 3, 50))\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_train_time = time.time() - start_time\n",
    "\n",
    "print(f\"Optimal alpha: {ridge_model.alpha_:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Ridge\n",
    "start_time = time.time()\n",
    "\n",
    "ridge_pred_train = ridge_model.predict(X_train_scaled)\n",
    "ridge_pred_temporal = ridge_model.predict(X_temporal_scaled)\n",
    "ridge_pred_spatial = ridge_model.predict(X_spatial_scaled)\n",
    "\n",
    "ridge_train_metrics = evaluate_model(y_train, ridge_pred_train, 'Train')\n",
    "ridge_temporal_metrics = evaluate_model(y_temporal, ridge_pred_temporal, 'Temporal')\n",
    "ridge_spatial_metrics = evaluate_model(y_spatial, ridge_pred_spatial, 'Spatial')\n",
    "\n",
    "ridge_inference_time = time.time() - start_time\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Ridge',\n",
    "    'Train_RMSE': ridge_train_metrics['RMSE'],\n",
    "    'Train_R2': ridge_train_metrics['R2'],\n",
    "    'Temporal_RMSE': ridge_temporal_metrics['RMSE'],\n",
    "    'Temporal_R2': ridge_temporal_metrics['R2'],\n",
    "    'Spatial_RMSE': ridge_spatial_metrics['RMSE'],\n",
    "    'Spatial_R2': ridge_spatial_metrics['R2'],\n",
    "    'Train_Time': ridge_train_time,\n",
    "    'Inference_Time': ridge_inference_time\n",
    "})\n",
    "\n",
    "print(f\"\\nRidge Model trained in {ridge_train_time:.4f}s\")\n",
    "print(f\"Train RMSE: {ridge_train_metrics['RMSE']:.2f}, R²: {ridge_train_metrics['R2']:.4f}\")\n",
    "print(f\"Temporal RMSE: {ridge_temporal_metrics['RMSE']:.2f}, R²: {ridge_temporal_metrics['R2']:.4f}\")\n",
    "print(f\"Spatial RMSE: {ridge_spatial_metrics['RMSE']:.2f}, R²: {ridge_spatial_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623a918",
   "metadata": {},
   "source": [
    "## Part I: Task 3 - Model Comparison (Horserace Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba94921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# HORSERACE TABLE: Model Comparison\n",
    "# =====================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display formatted table\n",
    "print(\"=\" * 100)\n",
    "print(\"HORSERACE TABLE: Model Comparison\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Round numeric columns for display\n",
    "display_df = results_df.copy()\n",
    "display_df['Train_RMSE'] = display_df['Train_RMSE'].round(2)\n",
    "display_df['Temporal_RMSE'] = display_df['Temporal_RMSE'].round(2)\n",
    "display_df['Spatial_RMSE'] = display_df['Spatial_RMSE'].round(2)\n",
    "display_df['Train_R2'] = display_df['Train_R2'].round(4)\n",
    "display_df['Temporal_R2'] = display_df['Temporal_R2'].round(4)\n",
    "display_df['Spatial_R2'] = display_df['Spatial_R2'].round(4)\n",
    "display_df['Train_Time'] = display_df['Train_Time'].apply(lambda x: f'{x:.2f}s')\n",
    "display_df['Inference_Time'] = display_df['Inference_Time'].apply(lambda x: f'{x:.4f}s')\n",
    "\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "# Highlight best models\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"BEST MODELS BY METRIC:\")\n",
    "print(\"=\" * 100)\n",
    "best_train_rmse = results_df.loc[results_df['Train_RMSE'].idxmin(), 'Model']\n",
    "best_temporal_rmse = results_df.loc[results_df['Temporal_RMSE'].idxmin(), 'Model']\n",
    "best_spatial_rmse = results_df.loc[results_df['Spatial_RMSE'].idxmin(), 'Model']\n",
    "print(f\"Lowest Train RMSE: {best_train_rmse} ({results_df['Train_RMSE'].min():.2f})\")\n",
    "print(f\"Lowest Temporal RMSE: {best_temporal_rmse} ({results_df['Temporal_RMSE'].min():.2f})\")\n",
    "print(f\"Lowest Spatial RMSE: {best_spatial_rmse} ({results_df['Spatial_RMSE'].min():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74dd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Visualization of model performance\n",
    "# Following course material visualization patterns\n",
    "# =====================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "\n",
    "axes[0].bar(x - width, results_df['Train_RMSE'], width, label='Train', color='steelblue')\n",
    "axes[0].bar(x, results_df['Temporal_RMSE'], width, label='Temporal', color='darkorange')\n",
    "axes[0].bar(x + width, results_df['Spatial_RMSE'], width, label='Spatial', color='green')\n",
    "axes[0].set_ylabel('RMSE (price)')\n",
    "axes[0].set_title('RMSE by Model and Dataset')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(linestyle=':')\n",
    "\n",
    "# R² comparison\n",
    "axes[1].bar(x - width, results_df['Train_R2'], width, label='Train', color='steelblue')\n",
    "axes[1].bar(x, results_df['Temporal_R2'], width, label='Temporal', color='darkorange')\n",
    "axes[1].bar(x + width, results_df['Spatial_R2'], width, label='Spatial', color='green')\n",
    "axes[1].set_ylabel('R²')\n",
    "axes[1].set_title('R² by Model and Dataset')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(linestyle=':')\n",
    "\n",
    "# Training time (as in course material)\n",
    "axes[2].bar(results_df['Model'], results_df['Train_Time'], color='purple')\n",
    "axes[2].set_ylabel('Time (seconds)')\n",
    "axes[2].set_title('Training Time')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a50b7",
   "metadata": {},
   "source": [
    "### Discussion: Model Performance\n",
    "\n",
    "**The overfitting story:**\n",
    "\n",
    "Look at Random Forest and Gradient Boosting — they crush the training data (RMSE ~476-480) but only marginally beat linear models on the holdout (~514-516 vs ~519). Classic overfitting pattern. The tree-based methods are memorizing quirks of the training data that don't generalize.\n",
    "\n",
    "**Linear models are surprisingly competitive:**\n",
    "\n",
    "OLS, LASSO, and Ridge all land within a few RMSE points of each other on holdout data. LASSO only zeroed out 9 of 53 coefficients, suggesting most features carry *some* signal. The \"keep it simple\" approach works okay here.\n",
    "\n",
    "**Spatial transfer is the real test:**\n",
    "\n",
    "All models jump to ~622 RMSE on Oslo. That ~100 point gap from Copenhagen holdout tells you: market-specific factors matter. Maybe Oslo has different neighborhood premiums, or the mix of property types differs. Still, a model trained on Copenhagen gets you \"in the ballpark\" for Oslo.\n",
    "\n",
    "**What would I do in production?**\n",
    "\n",
    "Honestly, I'd probably go with LASSO or Ridge. The tree models' marginal accuracy gains don't justify the complexity and training time, especially if the model needs to be explainable to a business stakeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb71a2",
   "metadata": {},
   "source": [
    "## Part I: Task 4 - Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9548b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Random Forest feature importance (following class-16)\n",
    "# =====================================================\n",
    "\n",
    "# Get feature importances from best estimator\n",
    "rf_best = rf_model.best_estimator_\n",
    "\n",
    "df_rf_var_imp = pd.DataFrame({\n",
    "    'variable': X_train.columns,\n",
    "    'imp': rf_best.feature_importances_\n",
    "}).sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_rf_var_imp['cumulative_imp'] = df_rf_var_imp['imp'].cumsum()\n",
    "\n",
    "# Display formatted (following class-16 pattern)\n",
    "df_display = df_rf_var_imp.head(15).copy()\n",
    "df_display['imp'] = df_display['imp'].apply(lambda x: f'{x:.1%}')\n",
    "df_display['cumulative_imp'] = df_display['cumulative_imp'].apply(lambda x: f'{x:.1%}')\n",
    "print(\"Random Forest - Top 15 Feature Importances\")\n",
    "print(df_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Gradient Boosting feature importance\n",
    "# =====================================================\n",
    "\n",
    "gb_best = gb_model.best_estimator_\n",
    "\n",
    "df_gb_var_imp = pd.DataFrame({\n",
    "    'variable': X_train.columns,\n",
    "    'imp': gb_best.feature_importances_\n",
    "}).sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_gb_var_imp['cumulative_imp'] = df_gb_var_imp['imp'].cumsum()\n",
    "\n",
    "# Display formatted\n",
    "df_display = df_gb_var_imp.head(15).copy()\n",
    "df_display['imp'] = df_display['imp'].apply(lambda x: f'{x:.1%}')\n",
    "df_display['cumulative_imp'] = df_display['cumulative_imp'].apply(lambda x: f'{x:.1%}')\n",
    "print(\"Gradient Boosting - Top 15 Feature Importances\")\n",
    "print(df_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62679838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Plot feature importance (following class-16 pattern)\n",
    "# Only show variables with importance > 1%\n",
    "# =====================================================\n",
    "\n",
    "cutoff = 0.01\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Random Forest (left)\n",
    "ax1 = df_rf_var_imp[df_rf_var_imp.imp > cutoff]\\\n",
    "    .sort_values(by='imp')\\\n",
    "    .plot(kind='barh', x='variable', y='imp', \n",
    "          ax=axes[0], legend=False, color='steelblue')\n",
    "axes[0].set_title('Random Forest - Feature Importances (>1%)')\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "\n",
    "# Gradient Boosting (right)\n",
    "ax2 = df_gb_var_imp[df_gb_var_imp.imp > cutoff]\\\n",
    "    .sort_values(by='imp')\\\n",
    "    .plot(kind='barh', x='variable', y='imp', \n",
    "          ax=axes[1], legend=False, color='darkorange')\n",
    "axes[1].set_title('Gradient Boosting - Feature Importances (>1%)')\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e411054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Compare top 10 features between RF and GB\n",
    "# =====================================================\n",
    "\n",
    "rf_top10 = set(df_rf_var_imp.head(10)['variable'])\n",
    "gb_top10 = set(df_gb_var_imp.head(10)['variable'])\n",
    "\n",
    "overlap = rf_top10.intersection(gb_top10)\n",
    "rf_only = rf_top10 - gb_top10\n",
    "gb_only = gb_top10 - rf_top10\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE COMPARISON: Top 10 Features\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFeatures in BOTH top 10 ({len(overlap)}):\")\n",
    "for f in sorted(overlap):\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(f\"\\nRandom Forest only ({len(rf_only)}):\")\n",
    "for f in sorted(rf_only):\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(f\"\\nGradient Boosting only ({len(gb_only)}):\")\n",
    "for f in sorted(gb_only):\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f46926",
   "metadata": {},
   "source": [
    "### Discussion: Feature Importance\n",
    "\n",
    "**What's driving prices?**\n",
    "\n",
    "No surprises here — both RF and GB agree that **capacity** (accommodates, beds, bathrooms) dominates. The squared accommodates term ranks high too, which confirms that pricing isn't linear in capacity. Going from 2→4 guests probably adds more value than 6→8.\n",
    "\n",
    "**Room type matters a lot.** Private rooms are priced very differently from entire homes, which makes sense. Nobody expects to pay full-apartment prices for a room in someone's house.\n",
    "\n",
    "**Review metrics show up** but aren't the top drivers. I think this is because reviews proxy for quality, but capacity proxies for what you're actually getting. A 5-star closet is still a closet.\n",
    "\n",
    "**Amenities are less important than I expected.** Washer, dryer, TV — they matter, but they're not game-changers. Maybe because most Copenhagen/Oslo listings already have basic amenities? In a market with more variance (budget hostels vs luxury villas), amenities might matter more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77546a",
   "metadata": {},
   "source": [
    "## Part II: Task 5 & 6 - External Validation Summary\n",
    "\n",
    "The external validation results are already incorporated in the horserace table above.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**Temporal Validation (Copenhagen Sept 2025):**\n",
    "- This is a real 6-month time gap from the training data (March → September)\n",
    "- Performance here tells us if the model captures durable pricing patterns or just memorized a snapshot\n",
    "- Seasonal effects matter: September might have different tourism patterns than March\n",
    "\n",
    "**Spatial Validation (Oslo Sept 2025):**\n",
    "- Same time period as temporal test, but different market\n",
    "- This isolates the \"location effect\" — if spatial is worse than temporal, it's geography causing the gap, not time\n",
    "\n",
    "**Comparing temporal vs spatial:**\n",
    "\n",
    "This setup is nice because we can actually separate time and location effects:\n",
    "- If temporal >> spatial: the model struggles with new locations more than new time periods\n",
    "- If temporal ≈ spatial: both forms of generalization are similarly challenging\n",
    "- If temporal << spatial: time drift hurts more than location shift (would be surprising)\n",
    "\n",
    "My expectation: spatial validation will be harder because Oslo and Copenhagen, while both Nordic capitals, have different neighborhood structures, price levels, and currency (NOK vs DKK). The model was never trained on Oslo-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edd4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# FINAL SUMMARY\n",
    "# =====================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTraining data: Copenhagen March 2025 ({len(df_train):,} observations)\")\n",
    "print(f\"Temporal validation: Copenhagen Sept 2025 ({len(df_temporal):,} observations)\")\n",
    "print(f\"Spatial validation: Oslo Sept 2025 ({len(df_spatial):,} observations)\")\n",
    "print(f\"\\nNumber of features: {X_train.shape[1]}\")\n",
    "print(f\"Target variable: price (in local currency)\")\n",
    "print(\"\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. TRAINING PERFORMANCE:\n",
    "   - Tree-based models (RF, GB) typically achieve lower training RMSE\n",
    "   - This reflects their higher flexibility/capacity\n",
    "\n",
    "2. TEMPORAL GENERALIZATION (Copenhagen March → Sept):\n",
    "   - Tests if pricing patterns persist across 6 months\n",
    "   - Seasonal effects and market changes between Q1 and Q3\n",
    "\n",
    "3. SPATIAL GENERALIZATION (Copenhagen → Oslo):\n",
    "   - Tests if pricing patterns transfer across cities\n",
    "   - Both are Nordic capitals but different markets/currencies\n",
    "\n",
    "4. MODEL SELECTION:\n",
    "   - If interpretability matters: OLS, LASSO, or Ridge\n",
    "   - If prediction accuracy matters: Random Forest or Gradient Boosting\n",
    "   - Best overall: Consider the model with best holdout performance\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8203efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('model_results.csv', index=False)\n",
    "print(\"Results saved to model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a937e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AI Declaration\n",
    "\n",
    "This assignment was completed with assistance from AI tools (GitHub Copilot and Gemini CLI) in accordance with the course AI policy.\n",
    "\n",
    "**What AI was used for:**\n",
    "- Writing and debugging Python code (data preprocessing, model fitting, evaluation loops)\n",
    "- Code refactoring to match course material patterns (variable naming conventions like `n_`, `f_`, `d_` prefixes)\n",
    "- Generating boilerplate code for visualization and model comparison tables\n",
    "- Fixing errors (e.g., the categorical variable mismatch with patsy that required harmonizing category levels)\n",
    "\n",
    "**What I did myself:**\n",
    "- Deciding on the analysis strategy and interpreting results\n",
    "- Choosing which models to compare and why (e.g., Ridge as the 5th model to complement LASSO)\n",
    "- Writing the discussion sections and explaining decision points\n",
    "- Verifying all code outputs make sense and checking the logic\n",
    "\n",
    "**Responsibility:**\n",
    "I reviewed all AI-generated code and take full responsibility for the final submission. Any errors in the analysis or interpretation are mine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceu-data-analysis-3-assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
